{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m pip install opencv-python scipy sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "import functools\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from tcim.transforms import translation, rotation, flip, scale, noise\n",
    "from tcim.moments import get_moments, compare_moments, ShowAndCompareMoments\n",
    "from tcim.utils import PrintSection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sample image\n",
    "@functools.lru_cache(1)\n",
    "def get_sample_image():\n",
    "    img = cv2.imread('test_image.webp', cv2.IMREAD_GRAYSCALE)\n",
    "    return cv2.resize(img, (400, 300))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Demonstrate different transforms\n",
    "def transformation_examples():\n",
    "    img = get_sample_image()\n",
    "    action_dict = {\n",
    "        'original': lambda x: x.copy(),\n",
    "        'translated': functools.partial(translation, x=50, y=100),\n",
    "        'rotated': functools.partial(rotation, degree=90),\n",
    "        'scaled': functools.partial(scale, scale_x=0.5, scale_y=0.5),\n",
    "        'flipped': functools.partial(flip, flip_type='vertical'),\n",
    "        'noised': functools.partial(noise, intensity=0.1),\n",
    "    }\n",
    "\n",
    "    with ShowAndCompareMoments() as s:\n",
    "        for tag, action in action_dict.items():\n",
    "            img = action(img)\n",
    "            s.record(img, tag)\n",
    "\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "transformation_examples()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define random transforms\n",
    "random_apply_methods = {\n",
    "    'identical': lambda img: img.copy(),\n",
    "    'translation': lambda img: translation(img, random.randrange(20, 100), random.randrange(20, 100)),\n",
    "    'rotation_90_180_270': lambda img: rotation(img, random.choice([90, 180, 270])),\n",
    "    'rotation_any': lambda img: rotation(img, random.randrange(0, 360)),\n",
    "    'flip': lambda img: flip(img, random.choice(['horizontal', 'vertical'])),\n",
    "    'scale': lambda img: scale(img, random.uniform(0.5, 1.5), random.uniform(0.5, 1.5)),\n",
    "    'gaussian_noise': lambda img: noise(img, random.uniform(0.1, 0.5)),\n",
    "}\n",
    "\n",
    "\n",
    "def random_apply(img) -> Tuple[int, np.ndarray]:\n",
    "    i = random.randrange(0, len(random_apply_methods))\n",
    "    return i, random_apply_methods[list(random_apply_methods.keys())[i]](img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "def load_dataset():\n",
    "    dataset_path = Path('dataset.json')\n",
    "    if dataset_path.exists():\n",
    "        return json.loads(dataset_path.read_text())\n",
    "    else:\n",
    "        with PrintSection('Constructing dataset'):\n",
    "            raw_img = get_sample_image()\n",
    "            dataset = {'x': [], 'y': []}\n",
    "            for _ in range(5000):\n",
    "                _, img1 = random_apply(raw_img)\n",
    "                y, img2 = random_apply(img1)\n",
    "                x = compare_moments(get_moments(img1), get_moments(img2))\n",
    "                dataset['x'].append(list(x.values()))\n",
    "                dataset['y'].append(y)\n",
    "            dataset_path.write_text(json.dumps(dataset))\n",
    "        return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ten fold validation\n",
    "def ten_fold_validation():\n",
    "    dataset = load_dataset()\n",
    "    tree = DecisionTreeClassifier()\n",
    "    with PrintSection('Ten fold validation'):\n",
    "        cvs = cross_val_score(tree, dataset['x'], dataset['y'], cv=10)\n",
    "        print(f'ten fold accuracy scores: {cvs}')\n",
    "        print(f'ten fold average score: {sum(cvs)/len(cvs)}')\n",
    "\n",
    "ten_fold_validation()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Demo\n",
    "def demonstration():\n",
    "    dataset = load_dataset()\n",
    "    tree = DecisionTreeClassifier()\n",
    "    tree.fit(dataset['x'], dataset['y'])\n",
    "    raw_img = get_sample_image()\n",
    "    transform_types = list(random_apply_methods.keys())\n",
    "    for i in range(100):\n",
    "        with PrintSection(f'Demo {i}'):\n",
    "            _, img1 = random_apply(raw_img)\n",
    "            y, img2 = random_apply(img1)\n",
    "            x = compare_moments(get_moments(img1), get_moments(img2))\n",
    "            y_hat = tree.predict([list(x.values())])[0]\n",
    "            print(f'Truth: {transform_types[y]}, Predicted: {transform_types[y_hat]}')\n",
    "            img1 = cv2.putText(\n",
    "                img1, f'Truth: {transform_types[y]}', (0, 20),\n",
    "                fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1.5, color=(255, ), thickness=2\n",
    "            )\n",
    "            img2 = cv2.putText(\n",
    "                img2, f'Predict: {transform_types[y_hat]}', (0, 20),\n",
    "                fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1.5, color=(255,), thickness=2\n",
    "            )\n",
    "            cv2.imshow('Before', img1)\n",
    "            cv2.imshow('After', img2)\n",
    "            key = cv2.waitKey()\n",
    "            cv2.destroyAllWindows()\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "demonstration()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
